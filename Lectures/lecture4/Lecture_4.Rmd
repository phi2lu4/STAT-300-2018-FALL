---
title: "Building statistical models"
date: "October 19, 2018"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(broom)
library(modelr)
survey <- read_csv("data/StudentSurvey.csv")
```

# Introduction to Modeling

- *Goal of a model:* a simple low-dimensional summary of a dataset.

  - capture the true "signals" (i.e., patterns generated by the phenomenon of interest)
  
  - ignore "noise" (i.e., random chance/variation that you're not interested in)
  
--
  
- Purpose of building a model:

  - To test/confirm a hypothesis
  
  - To make a prediction
  
--

- Typically, we use all available data for confirming a hypothesis, while splitting data when building predictive model

---
# Predictive modeling

- "Essentially, all models are wrong, but some are useful" -- George Box

--

- Building many models and pick a few useful ones. But how to know they are useful?

  - Many metrics to evaluate a model (e.g., R-squares)

  - Ideal for predictive model: how accurate the prediction is.
  
---
# Evaluate predictive models

- Ideal world: new observations are available to evaluate the model

  - Popular metrics: predictive MSE, predictive RMSE, etc.
  
--

- In practice, new observations are not usually available

   - Split the data and reserve a part as "new observations"
   
   - Data used to fit models is called **training set**, the other is called **test set**
   
--

- Complication: Less data = less accuracy
  
  - The typical splitting ratio: 80/20, 70/30, 50/50.... depending on the size of the available dataset.
  
  - Several methods to estimate the predictive MSE use only training set (e.g, AIC, BIC, etc.)
  
---
# Model basics

Two parts to a model:

1. **Family of models:**  a precise, but generic, pattern that you want to capture.
  
  - Example: a straight line, or a quadratic curve.
  
  - Example: `y = a_1 * x + a_2` or `y = a_1 * x ^ a_2`, where `x` and `y` are known variables from the data.
  
2. **Fitted model:** one specified model from the family that is the closest to your data

  - Example: `y = 3 * x + 7` or `y = 9 * x ^ 2`.
  
--

- Analyst's job: 

  - Find all the sensible families of models (domain knowledge is the main driving force)
  
  - Compute and evaluate fitted models from all candidate families.
  
---
# Fitting a simple model in R

- Dataset: a survey on 362 introductory statistics students at a university in several years

- Wish to predict their GPA

- The simple model is:

```{r}
mod <- lm(GPA ~ SAT, data = survey)
summary(mod)
```

---
# Useful R packages to examine a model

- `dplyr` (part of `tidyverse`): data splitting

```{r}
train <- survey %>% sample_frac(.7)
test <- survey %>% setdiff(train)
nrow(train)
nrow(test)
```

- Use `sample_n()` to select a fixed number of observations.
---
# Useful R packages to examine a model

- `broom` package: tidy the output of the model 

```{r}
mod <- lm(GPA ~ SAT, data = train)
tidy(mod)
```

- Useful functions are `augment()` (add disgnostic statistics) and `glance()` (show model statistics).

---
# Useful R packages to examine a model
  
- `modelr`: provides utilities to compute model statistics

```{r}
test %>% add_predictions(mod) %>% select(GPA, pred) %>% slice(1:3)
```

- `modelr` includes several often-used model quality metrics: `rmse`, `mae`, etc.

```{r}
rmse(mod, test)
```

